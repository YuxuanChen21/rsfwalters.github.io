<!DOCTYPE html>
<html>

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>
        Geometric Learning Lab - NEU
    </title>

    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="stylesheet" href="../css/main.css">
    <link rel="canonical" href="/">

</head>

<body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>
        <!-- Nav Bar -->
        <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="container">
                <!-- Navbar Toggle -->
                <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar top-bar"></span>
                    <span class="icon-bar middle-bar"></span>
                    <span class="icon-bar bottom-bar"></span>
                </button>
                <div class="collapse navbar-collapse text-right" id="navbarNav">
                    <ul class="navbar-nav ml-auto flex-nowrap">
                        <!-- About -->
                        <li class="nav-item active">
                            <a class="nav-link" href="../index.html">
                                Home              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="geometric-learning-lab.html">
                                Research              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="teaching.html">
                                Teaching              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <!-- <li class="nav-item active">
                            <a class="nav-link" href="/">
                                Contact              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li> -->

                    </ul>
                </div>
            </div>
        </nav>

    </header>


    <!-- Content -->

    <div class="container mt-5">
        <div class="post">

            <header class="post-header">
                <h1 class="post-title-research-page">
                    <span class="font-weight-bold">Geometric Learning Lab</span>
                </h1>
                <p class="desc"></p>
            </header>

            <article>

                <div class="clearfix">
                    <p>
                        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
                    </p>

                    <p>
                        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Lorem ipsum dolor sit
                        amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Lorem ipsum dolor
                        sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Lorem ipsum dolor
                        sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
                    </p>

                    <p>
                        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
                    </p>

                </div>

            </article>

            <article>

                <header class="post-header">
                    <h1 class="post-title-research-page">
                        <span class="font-weight-bold">Lab Members</span>
                    </h1>
                    <p class="desc"></p>
                </header>

                <div class="gallery">
                    <figure class="gallery_item">
                        <img src="../images/david-klee.jpg" class="gallery_img " alt="David Klee">
                        <figcaption class="figcaption"><a href="https://dmklee.github.io/" target="_blank">David Klee</a></figcaption>
                    </figure>

                    <figure class="gallery_item">
                        <img src="../images/dian.jpg" class="gallery_img " alt="Dian Wang">
                        <figcaption class="figcaption"><a href="https://pointw.github.io">Dian Wang</a></figcaption>
                    </figure>

                    <figure class="gallery_item">
                        <img src="../images/john.png" class="gallery_img " alt="Jung Yeon Park">
                        <figcaption class="figcaption"><a href="https://jypark0.github.io/">Jung Yeon Park</a></figcaption>
                    </figure>

                    <figure class="gallery_item">
                        <img src="../images/vedanshi-shah.jpg" class="gallery_img " alt="Vedanshi Shah">
                        <figcaption class="figcaption"><a href="https://shahve.wixsite.com/vedanshi" target="_blank">Vedanshi Shah</a></figcaption>
                    </figure>

                    <figure class="gallery_item">
                        <img src="../images/rw-1.jpg" class="gallery_img " alt="Robin Walters">
                        <figcaption class="figcaption"><a href="index.html">Robin Walters</a></figcaption>
                    </figure>

                    <figure class="gallery_item">
                        <img src="../images/rw-1.jpg" class="gallery_img " alt="Robin Walters">
                        <figcaption class="figcaption"><a href="index.html">Robin Walters</a></figcaption>
                    </figure>

                    <figure class="gallery_item">
                        <img src="../images/rw-1.jpg" class="gallery_img " alt="Robin Walters">
                        <figcaption class="figcaption"><a href="index.html">Robin Walters</a></figcaption>
                    </figure>

                    <figure class="gallery_item">
                        <img src="../images/rw-1.jpg" class="gallery_img " alt="Robin Walters">
                        <figcaption class="figcaption"><a href="index.html">Robin Walters</a></figcaption>
                    </figure>

                </div>

            </article>

            <article>

                <header class="post-header">
                    <h1 class="post-title-research-page">
                        <span class="font-weight-bold">Selected Publications</span>
                    </h1>
                    <p class="desc"></p>
                </header>

                <div class="publications">

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Under Review</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/surprising-effectiveness.gif" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="#" target="_blank" rel="noopener noreferrer">Neel Sortur</a>,
                                        <a href="#" target="_blank" rel="noopener noreferrer">Lawson L.S. Wong</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt*</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Under Review</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.09231.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://pointw.github.io/extrinsic_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Extensive work has demonstrated that equivariant neural networks can significantly improve sample efficiency and generalization by enforcing an inductive bias in the network architecture. These applications
                                            typically assume that the domain symmetry is fully described by explicit transformations of the model inputs and outputs. However, many real-life applications contain only latent or partial symmetries which
                                            cannot be easily described by simple transformations of the input. In these cases, it is necessary to learn symmetry in the environment instead of imposing it mathematically on the network architecture. We discover,
                                            surprisingly, that imposing equivariance constraints that do not exactly match the domain symmetry is very helpful in learning the true symmetry in the environment. We differentiate between extrinsic and incorrect
                                            symmetry constraints and show that while imposing incorrect symmetry can impede the model's performance, imposing extrinsic symmetry can actually improve performance. We demonstrate that an equivariant model
                                            can significantly outperform non-equivariant methods on domains with latent symmetries both in supervised learning and in reinforcement learning for robotic manipulation and control problems.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Under Review</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/seil.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">SEIL: Simulation-augmented Equivariant Imitation Learning</div>
                                    <div class="author">
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia*</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="https://xxs90.github.io/" target="_blank" rel="noopener noreferrer">Guanang Su</a>,
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David Klee</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Under Review</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.00194.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://saulbatman.github.io/project/seil/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: In robotic manipulation, acquiring samples is extremely expensive because it often requires interacting with the real world. Traditional image-level data augmentation has shown the potential to improve
                                            sample efficiency in various machine learning tasks. However, image-level data augmentation is insufficient for an imitation learning agent to learn good manipulation policies in a reasonable amount of demonstrations.
                                            We propose Simulation-augmented Equivariant Imitation Learning (SEIL), a method that combines a novel data augmentation strategy of supplementing expert trajectories with simulated transitions and an equivariant
                                            model that exploits the O(2) symmetry in robotic manipulation. Experimental evaluations demonstrate that our method can learn non-trivial manipulation tasks within ten demonstrations and outperforms the baselines
                                            with a significant margin.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Under Review</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/Edge-grasp-networks.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Edge Grasp Network: Graph-Based SE(3)-invariant Approach to Grasp Detection</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupend Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Under Review</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.00191.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://haojhuang.github.io/edge_grasp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Given point cloud input, the problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. This important problem has many practical
                                            applications. Here we propose a novel method and neural network model that enables better grasp success rates relative to what is available in the literature. The method takes standard point cloud data as input
                                            and works well with single-view point clouds observed from arbitrary viewing directions.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICML 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/sen.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Learning Symmetric Embedding Networks for Equivariant World Models</div>
                                    <div class="author">
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://sites.google.com/view/obiza" target="_blank" rel="noopener noreferrer">Ondrej Biza</a>,
                                        <a href="https://lfzhao.com/" target="_blank" rel="noopener noreferrer">Linfeng Zhao</a>,
                                        <a href="https://jwvdm.github.io/" target="_blank" rel="noopener noreferrer">Jan-Willem van de Meent</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>We propose learning symmetric embedding networks (SENs) for input spaces where we do not know the effects of symmetry transformations, to a feature space where the transformation is known. This network can be combined with downstream task-specific equivariant networks and trained end-to-end in latent space. SENs can extend the applicability of equivariant networks to a wider variety of domains.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2204.11371" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://github.com/jypark0/sen" class="btn btn-sm z-depth-0" role="button">Code</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations
                                            act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know
                                            the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an
                                            explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application
                                            of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">PMLR Vol. 197</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr>
                                    <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/image-to-icosahedral.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Image to Icosahedral Projection for SO(3) Object Reasoning from Single-View Images</div>
                                    <div class="author">
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David M. Klee</a>,
                                        <a href="https://sites.google.com/view/obiza" target="_blank" rel="noopener noreferrer">Ondrej Biza</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>We develop a hybrid equivariant model that incorporates SO(2) and SO(3) equivariant convolution layers to improve 3D reasoning from 2D images.   Our method outperforms baselines on shape classification and pose prediction tasks, especially in the low-data regime.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2207.08925" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/dmklee/image2icosahedral" target="_blank" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://dmklee.github.io/image2icosahedral/" target="_blank" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Reasoning about 3D objects based on 2D images is challenging due to variations in appearance caused by viewing the object from different orientations. Tasks such as object classification are invariant
                                            to 3D rotations and other such as pose estimation are equivariant. However, imposing equivariance as a model constraint is typically not possible with 2D image input because we do not have an a priori model
                                            of how the image changes under out-of-plane object rotations. The only SO(3)-equivariant models that currently exist require point cloud or voxel input rather than 2D images. In this paper, we propose a novel
                                            architecture based on icosahedral group convolutions that reasons in SO(3) by learning a projection of the input image onto an icosahedron. The resulting model is approximately equivariant to rotation in SO(3).
                                            We apply this model to object pose estimation and shape classification tasks and find that it outperforms reasonable baselines.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">RLDM 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr>
                                    <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/understanding-the-mechanisms.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Understanding the Mechanism behind Data Augmentation's Success on Image-based RL
                                    </div>
                                    <div class="author">
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David M. Klee</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Data augmentation is known to provide substantial benefits for image-based reinforcement learning (RL) but the mechanism is not clear.  We show that data augmentation increases both the equivariance and invariance of the convolutional encoder, e.g. the feature map is spatially smooth.  We show that a simple Gaussian blur operation can achieve the same effect for some of the tested environments.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://dmklee.github.io/assets/publications/data_aug/paper.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://dmklee.github.io/assets/publications/data_aug/poster.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">Poster</a>
                                        <!-- <a href="https://dmklee.github.io/image2icosahedral/" target="_blank" class="btn btn-sm z-depth-0" role="button">Webpage</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Reinforcement learning for continuous control tasks is challenging with image observations, due to the representation learning problem. A series of recent work has shown that augmenting the observations
                                            via random shifts during training significantly improves performance, even matching state-based methods. However, it is not well-understood why augmentation is so beneficial; since the method uses a nearly-shift
                                            equivariant convolutional encoder, shifting the input should have little impact on what features are learned. In this work, we investigate why random shifts are useful augmentations for image-based RL and show
                                            that it increases both the shift-equivariance and shift-invariance of the encoder. In other words, the visual features learned exhibit spatial continuity, which we show can be partially achieved using dropout.
                                            We hypothesize that the spatial continuity of the visual encoding simplifies learning for the subsequent linear layers in the actor-critic networks.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <!-- <abbr class="badge">ICML</abbr> -->
                                    <abbr class="badge">ICLR 2022</abbr>
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/SO(2)-Equivariant-Reinforcement-Learning.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">SO(2)-Equivariant Reinforcement Learning</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Learning Representations 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2203.04439.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_rl_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Equivariant neural networks enforce symmetry within the structure of their convolutional layers, resulting in a substantial improvement in sample efficiency when learning an equivariant or invariant function.
                                            Such models are applicable to robotic manipulation learning which can often be formulated as a rotationally symmetric problem. This paper studies equivariant model architectures in the context of Q-learning
                                            and actor-critic reinforcement learning. We identify equivariant and invariant characteristics of the optimal Q-function and the optimal policy and propose equivariant DQN and SAC algorithms that leverage this
                                            structure. We present experiments that demonstrate that our equivariant versions of DQN and SAC can be significantly more sample efficient than competing algorithms on an important class of robotic manipulation
                                            problems.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">RSS 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/equi_transporter.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Transporter Network</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Robotics: Science and Systems 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2202.09400.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://haojhuang.github.io/etp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Transporter Net is a recently proposed framework for pick and place that is able to learn good manipulation policies from a very few expert demonstrations [35]. A key reason why Transporter Net is so sample
                                            efficient is that the model incorporates rotational equivariance into the pick-conditioned place module, i.e. the model immediately generalizes learned pick-place knowledge to objects presented in different
                                            pick orientations. This paper proposes a novel version of Transporter Net that is equivariant to both pick and place orientation. As a result, our model immediately generalizes pick-place knowledge to different
                                            place orientations in addition to generalizing the pick orientation as before. Ultimately, our new model is more sample efficient and achieves better pick and place success rates than the baseline Transporter
                                            Net model.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/On-Robot-Learning-With-Equivariant-Models.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">On-Robot Learning With Equivariant Models</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2203.04923.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_robot_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Recently, equivariant neural network models have been shown to improve sample efficiency for tasks in computer vision and reinforcement learning. This paper explores this idea in the context of on-robot
                                            policy learning in which a policy must be learned entirely on a physical robotic system without reference to a model, a simulator, or an offline dataset. We focus on applications of Equivariant SAC to robotic
                                            manipulation and explore a number of variations of the algorithm. Ultimately, we demonstrate the ability to learn several non-trivial manipulation tasks completely through on-robot experiences in less than an
                                            hour or two of wall clock time.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2021</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2021</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/Equivariant-Q-Learning-in-Spatial-Action-Spaces.png" alt="Project Image">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Q Learning in Spatial Action Spaces</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2021</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2110.15443.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_q_corl21" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_q_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Recently, a variety of new equivariant neural network model architectures have been proposed that generalize better over rotational and reflectional symmetries than standard models. These models are relevant
                                            to robotics because many robotics problems can be expressed in a rotationally symmetric way. This paper focuses on equivariance over a visual state space and a spatial action space - the setting where the robot
                                            action space includes a subset of SE(2). In this situation, we know a priori that rotations and translations in the state image should result in the same rotations and translations in the spatial action dimensions
                                            of the optimal policy. Therefore, we can use equivariant model architectures to make Q learning more sample efficient. This paper identifies when the optimal Q function is equivariant and proposes Q network
                                            architectures for this setting. We show experimentally that this approach outperforms standard methods in a set of challenging manipulation problems.

                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

            </article>

            </div>

        </div>

        <!-- Footer -->


        <footer class="sticky-bottom mt-5 ">
            <div class="container ">
                Made with <a href="http://jekyllrb.com/ " target="_blank " rel="noopener noreferrer ">Jekyll</a> and Bootstrap.
            </div>
        </footer>

</body>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>

<!-- Enable Tooltips -->
<script type="text/javascript">
    $(function() {
        $('[data-toggle="tooltip"]').tooltip()
    })
</script>

<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- MathJax -->
<script type="text/javascript">
    window.MathJax = {
        tex: {
            tags: 'ams'
        }
    };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-185703812-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-185703812-1');
</script>

<script>
    $(document).ready(function() {
        $('a.abstract').click(function() {
            $(this).parent().parent().find(".abstract.hidden").toggleClass('open');
        });
        $('a.bibtex').click(function() {
            $(this).parent().parent().find(".bibtex.hidden").toggleClass('open');
        });
        $('.navbar-nav').find('a').removeClass('waves-effect waves-light');
    });
</script>

</html>